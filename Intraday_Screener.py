# -*- coding: utf-8 -*-
"""
@Description: Aè‚¡ç›˜ä¸­å®æ—¶ç­›é€‰ (å®Œæ•´å¤åˆ»è„šæœ¬1: 8æ­¥ç­›é€‰+ä¸¥è‹›è´¢åŠ¡+è¯¦å°½æŠ¥å‘Š)
@RunTime: å»ºè®® 11:35 / 14:15
"""
import tushare as ts
import pandas as pd
import datetime
import time
import numpy as np
import talib
import requests
import json
import os
import traceback
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
TUSHARE_TOKEN = os.environ.get("TUSHARE_TOKEN", "")
FEISHU_WEBHOOK_URL = os.environ.get("FEISHU_WEBHOOK", "")

ts.set_token(TUSHARE_TOKEN)
pro = ts.pro_api()
API_CALL_DELAY = 0.02

# ================= è¾…åŠ©å‡½æ•° =================
def send_feishu_msg(title, content):
    if not FEISHU_WEBHOOK_URL:
        print(f"ã€æ¨¡æ‹Ÿå‘é€ã€‘{title}")
        print(content)
        return
    beijing_now = datetime.datetime.utcnow() + datetime.timedelta(hours=8)
    current_time = beijing_now.strftime('%m-%d %H:%M')
    full_text = f"ã€{title}ã€‘\n{current_time}\n{'='*20}\n{content}"
    
    # é£ä¹¦æ¶ˆæ¯åˆ†æ®µå‘é€ï¼Œé˜²æ­¢è¿‡é•¿
    # å¦‚æœå†…å®¹è¶…è¿‡300è¡Œæˆ–è€…å­—ç¬¦æ•°è¿‡å¤šï¼Œå¯ä»¥è€ƒè™‘åˆ‡åˆ†ï¼Œè¿™é‡Œå…ˆä¸€æ¬¡æ€§å‘
    headers = {'Content-Type': 'application/json'}
    try:
        requests.post(FEISHU_WEBHOOK_URL, headers=headers, data=json.dumps({"msg_type": "text", "content": {"text": full_text}}), timeout=15)
    except Exception as e: print(f"é£ä¹¦å‘é€æŠ¥é”™: {e}")

def get_beijing_now():
    return datetime.datetime.utcnow() + datetime.timedelta(hours=8)

def get_last_trade_day_history():
    now = get_beijing_now()
    check_date = now - datetime.timedelta(days=1)
    for _ in range(10):
        date_str = check_date.strftime('%Y%m%d')
        try:
            df = pro.trade_cal(exchange='', start_date=date_str, end_date=date_str)
            if not df.empty and df.iloc[0]['is_open'] == 1: return date_str
        except: pass
        check_date -= datetime.timedelta(days=1)
    return None

def calculate_dynamic_threshold(base_threshold=2.5):
    """åŠ¨æ€æ¢æ‰‹ç‡è®¡ç®—"""
    now = get_beijing_now()
    t_open = now.replace(hour=9, minute=30, second=0, microsecond=0)
    t_lunch_start = now.replace(hour=11, minute=30, second=0, microsecond=0)
    t_lunch_end = now.replace(hour=13, minute=0, second=0, microsecond=0)
    t_close = now.replace(hour=15, minute=0, second=0, microsecond=0)
    
    minutes = 0
    if now > t_open:
        if now <= t_lunch_start: minutes = (now - t_open).total_seconds() / 60
        elif now <= t_lunch_end: minutes = 120
        elif now <= t_close: minutes = 120 + (now - t_lunch_end).total_seconds() / 60
        else: minutes = 240
    
    ratio = max(0.05, min(1.0, minutes / 240.0))
    return round(base_threshold * ratio, 2), int(ratio * 100)

# ================= æ•°æ®è·å–å‡½æ•° =================

def get_realtime_snapshot(stock_basics_df):
    """è·å–å®æ—¶è¡Œæƒ…"""
    print(">> è·å–å®æ—¶è¡Œæƒ…...")
    code_map = {code.split('.')[0]: code for code in stock_basics_df['ts_code']}
    code_list = list(code_map.keys())
    realtime_dfs = []
    
    for i in tqdm(range(0, len(code_list), 800), desc="å®æ—¶ä¸‹è½½"):
        try:
            df = ts.get_realtime_quotes(code_list[i : i + 800])
            if df is not None and not df.empty: realtime_dfs.append(df)
            time.sleep(0.3)
        except: continue
            
    if not realtime_dfs: return pd.DataFrame()
    full = pd.concat(realtime_dfs, ignore_index=True)
    
    # æ¸…æ´—
    full['price'] = pd.to_numeric(full['price'], errors='coerce')
    full['pre_close'] = pd.to_numeric(full['pre_close'], errors='coerce')
    full['volume'] = pd.to_numeric(full['volume'], errors='coerce')
    full = full[full['price'] > 0].copy()
    full['ts_code'] = full['code'].map(code_map)
    
    if 'name' in full.columns: full = full.drop(columns=['name'])
    
    merged = pd.merge(full, stock_basics_df[['ts_code', 'name', 'float_share', 'total_share', 'industry']], on='ts_code', how='inner')
    
    # è®¡ç®—å®æ—¶æŒ‡æ ‡
    merged['turnover_rate_now'] = (merged['volume'] / (merged['float_share'] * 10000)) * 100
    merged['total_mv_now'] = merged['total_share'] * merged['price'] # å®æ—¶æ€»å¸‚å€¼(ä¸‡)
    
    return merged

def get_financial_data(ts_code, trade_date):
    """è·å–è´¢åŠ¡æ•°æ® (Step 4 & 7)"""
    try:
        # å°è¯•è·å–æœ€æ–°ä¸€æœŸå¹´æŠ¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·å–æœ€æ–°ä¸€æœŸå­£æŠ¥
        df_ind = pro.fina_indicator(ts_code=ts_code, limit=2, fields='end_date,profit_dedt,q_dtprofit')
        df_income = pro.income(ts_code=ts_code, limit=2, fields='end_date,revenue,report_type')
             
        if df_income.empty or df_ind.empty: return None
        
        # ç®€å•å–æœ€æ–°ä¸€æ¡éç©ºæ•°æ®
        rev = df_income.iloc[0]['revenue']
        prof_dedt = df_ind.iloc[0]['profit_dedt']
        
        if pd.isna(rev) or rev == 0: return None
        
        margin = prof_dedt / rev
        return {'revenue': rev, 'profit_dedt': prof_dedt, 'deducted_net_profit_margin': margin}
    except: return None

def get_holders_data(ts_code, trade_date):
    """è·å–è‚¡ä¸œäººæ•°å’Œå‰åå¤§ (Step 7.3)"""
    try:
        start_dt = (pd.to_datetime(trade_date) - datetime.timedelta(days=365)).strftime('%Y%m%d')
        
        df_h = pro.stk_holdernumber(ts_code=ts_code, start_date=start_dt)
        if df_h.empty: return None
        holder_num = df_h.sort_values('end_date', ascending=False).iloc[0]['holder_num']
        
        df_top10 = pro.top10_floatholders(ts_code=ts_code, start_date=start_dt)
        top10_sum = 0
        if not df_top10.empty:
            latest_date = df_top10['end_date'].max()
            top10_sum = df_top10[df_top10['end_date'] == latest_date]['hold_amount'].sum()
            
        return {'holder_num': holder_num, 'top10_shares': top10_sum}
    except: return None

def classify_growth(ts_code):
    """Step 7.4 å¢é•¿åˆ†ç±»"""
    try:
        df = pro.income(ts_code=ts_code, limit=5, fields='end_date,revenue')
        df_prof = pro.fina_indicator(ts_code=ts_code, limit=5, fields='end_date,profit_dedt')
        
        if len(df) < 2 or len(df_prof) < 2: return "æ•°æ®ä¸è¶³"
        
        rev_grow = df.iloc[0]['revenue'] > df.iloc[1]['revenue']
        prof_grow = df_prof.iloc[0]['profit_dedt'] > df_prof.iloc[1]['profit_dedt']
        
        if rev_grow and prof_grow: return "åŒå¢é•¿"
        if rev_grow: return "è¥æ”¶å¢"
        if prof_grow: return "å‡€åˆ©å¢"
        return "åŒé™"
    except: return "æœªçŸ¥"

def get_concept(ts_code):
    """è¡¥å……æ¦‚å¿µä¿¡æ¯ (ä»…å¯¹æœ€ç»ˆå…¥é€‰è€…è°ƒç”¨)"""
    try:
        df = pro.concept_detail(ts_code=ts_code)
        if not df.empty:
            # æ‹¼æ¥å‰3ä¸ªæ¦‚å¿µ
            concepts = df['concept_name'].unique()[:3]
            return ",".join(concepts)
    except: pass
    return "-"

# ================= æ ¸å¿ƒç­›é€‰é€»è¾‘ =================

def run_intraday_screener():
    print(">>> å¯åŠ¨å®Œæ•´ç‰ˆç›˜ä¸­ç­›é€‰ (Script 1)...")
    
    last_trade_day = get_last_trade_day_history()
    if not last_trade_day: return
    
    # 1. åŠ¨æ€é˜ˆå€¼
    BASE_THRESHOLD = 2.5
    dynamic_threshold, progress = calculate_dynamic_threshold(BASE_THRESHOLD)
    print(f"æ—¶é—´è¿›åº¦: {progress}%, åŠ¨æ€æ¢æ‰‹é˜ˆå€¼: >{dynamic_threshold}%")

    # 2. åŸºç¡€æ•°æ®
    print("è·å–åŸºç¡€æ•°æ®...")
    df_basic = pro.daily_basic(trade_date=last_trade_day, fields='ts_code,float_share,total_share')
    df_names = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
    df_base = pd.merge(df_basic, df_names, on='ts_code')
    
    # 3. å®æ—¶è¡Œæƒ… & Step 1 (æ¢æ‰‹ç‡)
    df_real = get_realtime_snapshot(df_base)
    if df_real.empty: 
        send_feishu_msg("é”™è¯¯", "æ— æ³•è·å–å®æ—¶è¡Œæƒ…")
        return
        
    df_pass1 = df_real[df_real['turnover_rate_now'] > dynamic_threshold].copy()
    print(f"Step 1 (æ¢æ‰‹ç‡) é€šè¿‡: {len(df_pass1)} åª")
    
    if df_pass1.empty:
        send_feishu_msg("ç›˜ä¸­ç­›é€‰", "æ— è‚¡ç¥¨æ»¡è¶³æ¢æ‰‹ç‡æ¡ä»¶")
        return

    # 4. å¾ªç¯å¤„ç† Step 2, 5, 6 (éœ€è¦å†å²Kçº¿)
    final_candidates = []
    process_list = df_pass1.sort_values('turnover_rate_now', ascending=False).head(300).to_dict('records')
    
    print("Step 2/5/6: å‡çº¿ä¸å½¢æ€åˆ†æ...")
    start_date_hist = (pd.to_datetime(last_trade_day) - datetime.timedelta(days=300)).strftime('%Y%m%d')
    
    for row in tqdm(process_list):
        ts_code = row['ts_code']
        curr_p = float(row['price'])
        
        try:
            df_hist = pro.daily(ts_code=ts_code, start_date=start_date_hist, end_date=last_trade_day)
        except: continue
        
        if df_hist is None or len(df_hist) < 120: continue
        df_hist = df_hist.sort_values('trade_date', ascending=True)
        
        closes = df_hist['close'].values.tolist()
        closes.append(curr_p)
        arr = np.array(closes)
        
        try:
            ma20 = talib.SMA(arr, 20)[-1]
            ma60 = talib.SMA(arr, 60)[-1]
            ma120 = talib.SMA(arr, 120)[-1]
        except: continue
        
        # Step 2: å®æ—¶ä»· > ä¸‰å‡çº¿
        if not (curr_p > ma20 and curr_p > ma60 and curr_p > ma120):
            continue
            
        # Step 6: æ˜¨æ—¥æ”¶ç›˜ä»·å½¢æ€
        try:
            prev_close = closes[-2]
            arr_prev = np.array(closes[:-1])
            ma20_prev = talib.SMA(arr_prev, 20)[-1]
            ma60_prev = talib.SMA(arr_prev, 60)[-1]
            ma120_prev = talib.SMA(arr_prev, 120)[-1]
            
            if not ((prev_close <= ma20_prev) or (prev_close <= ma60_prev) or (prev_close <= ma120_prev)):
                continue
        except: continue
        
        # Step 5: æŠµæ‰£ä»· (ç•¥å¾®ç®€åŒ–åˆ¤æ–­)
        try:
            deduction_cond = True
            if len(closes) > 20: 
                d20 = closes[-21]
                if d20 >= 1.2 * curr_p: deduction_cond = False
        except: pass
        
        # è®¡ç®— 7æ—¥æ¶¨è·Œå¹… (å½“å‰ä»· vs 7ä¸ªäº¤æ˜“æ—¥å‰)
        # closes[-1] is today, closes[-8] is 7 days ago? No, array index logic.
        # closes list length N. closes[-1] is now. closes[-1-N]
        day7_chg = 0.0
        if len(closes) >= 9: # è‡³å°‘è¦æœ‰å½“å¤©+è¿‡å»8å¤©
            c7 = closes[-9] # 7ä¸ªäº¤æ˜“æ—¥å‰çš„æ”¶ç›˜ä»·
            day7_chg = (curr_p - c7) / c7 * 100
        
        row['day_7_chg'] = day7_chg
        row['valuation_ratio'] = 0 
        row['strict_pass'] = False
        final_candidates.append(row)

    print(f"æŠ€æœ¯é¢ç­›é€‰é€šè¿‡: {len(final_candidates)} åª")
    
    if not final_candidates:
        send_feishu_msg("ç›˜ä¸­ç­›é€‰", "æŠ€æœ¯é¢(MA/å½¢æ€)ç­›é€‰åæ— ç»“æœ")
        return

    # 5. Step 4 & 7: ä¸¥è‹›è´¢åŠ¡ç­›é€‰
    print("Step 7: ä¸¥è‹›è´¢åŠ¡ç­›é€‰...")
    strict_results = []
    
    for row in tqdm(final_candidates):
        ts_code = row['ts_code']
        curr_p = row['price']
        
        fin = get_financial_data(ts_code, last_trade_day)
        if not fin: continue
        
        if fin['deducted_net_profit_margin'] <= 0.14: continue
        
        # ä¿®æ­£ä¼°å€¼æ¯”å•ä½é—®é¢˜ï¼šè¥æ”¶(å…ƒ) -> éœ€è¦è½¬æ¢ï¼Œå¸‚å€¼(ä¸‡)
        # å…¬å¼ï¼š( è¥æ”¶(å…ƒ)/10000 * (å‡€åˆ©ç‡/0.14) * 10 ) / æ€»å¸‚å€¼(ä¸‡)
        # æˆ–è€…ï¼š( è¥æ”¶(å…ƒ) * ... ) / (æ€»å¸‚å€¼(ä¸‡) * 10000)
        # è¿™é‡Œç»Ÿä¸€æŠŠè¥æ”¶è½¬ä¸ºä¸‡ï¼Œè¿™æ ·åˆ†å­åˆ†æ¯å•ä½ä¸€è‡´
        revenue_wan = fin['revenue'] / 10000.0
        
        if pd.isna(row['total_mv_now']) or row['total_mv_now'] == 0: continue
        
        val_ratio = (revenue_wan * (fin['deducted_net_profit_margin'] / 0.14) * 10) / row['total_mv_now']
        if val_ratio <= 1: continue
        
        row['valuation_ratio'] = val_ratio
        
        holders = get_holders_data(ts_code, last_trade_day)
        if not holders: continue
        
        float_shares_real = row['float_share'] * 10000 # æ¢å›è‚¡
        retail_shares = float_shares_real - holders['top10_shares']
        retail_holders = holders['holder_num'] - 10
        if retail_holders <= 0: continue
        
        per_capita_mv = (retail_shares * curr_p) / retail_holders
        if per_capita_mv <= 150000: continue
        
        row['growth'] = classify_growth(ts_code)
        row['per_capita_mv_wan'] = per_capita_mv / 10000.0
        row['concept'] = get_concept(ts_code) # ä»…å¯¹æœ€ç»ˆç»“æœè·å–æ¦‚å¿µ
        
        strict_results.append(row)

    # 6. ç”ŸæˆæŠ¥å‘Š
    df_final = pd.DataFrame(strict_results)
    
    msg_lines = []
    
    if not df_final.empty:
        # æŒ‰ä¼°å€¼æ¯”æ’åº
        df_final = df_final.sort_values('valuation_ratio', ascending=False)
        
        msg_lines.append(f"è¿›åº¦: {progress}% | åŠ¨æ€é˜ˆå€¼: >{dynamic_threshold}%")
        msg_lines.append(f"ä¸¥è‹›ç­›é€‰é€šè¿‡: {len(df_final)} åª")
        
        for i, row in df_final.head(15).iterrows(): # é™åˆ¶å±•ç¤ºå‰15åªï¼Œé˜²æ­¢å¤ªé•¿
            # æ•°æ®å‡†å¤‡
            code = row['ts_code']
            name = row['name']
            ind = row.get('industry', '-')
            concept = row.get('concept', '-')
            
            price = row['price']
            pre = float(row['pre_close'])
            pct_now = (price - pre) / pre * 100
            
            day7 = row.get('day_7_chg', 0)
            turn = row.get('turnover_rate_now', 0)
            val = row.get('valuation_ratio', 0)
            mv_per = row.get('per_capita_mv_wan', 0)
            growth = row.get('growth', '-')
            
            # æ„å»ºè¯¦å°½çš„å¡ç‰‡å¼å•è¡Œ
            # æ ¼å¼ï¼š
            # 1. åç§°(ä»£ç ) | è¡Œä¸š | å¢é•¿
            # 2. ç°ä»·(æ¶¨å¹…) | æ¢æ‰‹ | 7æ—¥
            # 3. ä¼°å€¼æ¯” | æˆ·å‡å¸‚å€¼ | æ¦‚å¿µ
            
            stock_block = (
                f"\nğŸ”´ **{name}** ({code}) | {ind} | {growth}\n"
                f"   ç°ä»·: {price:.2f} ({pct_now:+.2f}%) | æ¢æ‰‹: {turn:.2f}% | 7æ—¥: {day7:+.1f}%\n"
                f"   ä¼°å€¼æ¯”: {val:.2f} | æˆ·å‡: {mv_per:.1f}ä¸‡ | æ¦‚å¿µ: {concept}"
            )
            msg_lines.append(stock_block)
            
        if len(df_final) > 15:
            msg_lines.append(f"\n...å‰©ä½™ {len(df_final)-15} åªè¯·æŸ¥çœ‹ GitHub Artifacts CSV")
            
        # ä¿å­˜
        fname = f"Intraday_Strict_{datetime.datetime.now().strftime('%H%M')}.csv"
        df_final.to_csv(fname, index=False, encoding='utf-8-sig')
        print(f"CSVç”Ÿæˆ: {fname}")
        
    else:
        msg_lines.append(f"è¿›åº¦: {progress}% | é˜ˆå€¼: >{dynamic_threshold}%")
        msg_lines.append("æ— è‚¡ç¥¨é€šè¿‡ä¸¥è‹›è´¢åŠ¡ç­›é€‰ (æ‰£é>14% & ä¼°å€¼>1 & æˆ·å‡>15ä¸‡)")
        
        if final_candidates:
            msg_lines.append(f"\nğŸ’¡ [å¤‡é€‰] æŠ€æœ¯é¢é€šè¿‡ä½†è´¢åŠ¡æœªè¾¾æ ‡: {len(final_candidates)}åª")
            # ç®€ç•¥å±•ç¤ºå‰5
            top_tech = sorted(final_candidates, key=lambda x: x['turnover_rate_now'], reverse=True)[:5]
            for r in top_tech:
                pct = (r['price'] - float(r['pre_close'])) / float(r['pre_close']) * 100
                msg_lines.append(f"- {r['name']}: æ¶¨{pct:.1f}% æ¢{r['turnover_rate_now']:.1f}%")

    send_feishu_msg("ç›˜ä¸­ä¸¥è‹›ç­›é€‰ (Script 1)", "\n".join(msg_lines))
    print("æ‰§è¡Œå®Œæ¯•ã€‚")

if __name__ == "__main__":
    try:
        run_intraday_screener()
    except Exception as e:
        traceback.print_exc()
        send_feishu_msg("ç›˜ä¸­è„šæœ¬æŠ¥é”™", str(e))
